{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_processing.Datasets import get_maestro_dataset, collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from model.AE import FlexibleAE\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import muspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# training hyperparams\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# data hyperparams\n",
    "SEQ_LEN = 1000\n",
    "BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 10\n",
    "\n",
    "# model hyperparams\n",
    "NUM_TOKENS = 128\n",
    "DIM_MODEL = 512\n",
    "NUM_HEADS = 2\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "DROPOUT_P = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip downloading as the `.muspy.success` file is found.\n",
      "Skip extracting as the `.muspy.success` file is found.\n",
      "Skip conversion as the `.muspy.success` file is found.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_maestro_dataset(\"data/maestro\", representation=\"pitch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=partial(collate_fn, seq_len=SEQ_LEN, device=device),\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=EVAL_BATCH_SIZE,\n",
    "    collate_fn=partial(collate_fn, seq_len=SEQ_LEN, device=device),\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader Speed Experiment\n",
    "Iterating 10 batches takes 45 seconds. This could be a bottleneck. Ignoring for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n",
      "torch.Size([1000, 32])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    # We only need x\n",
    "    X = batch[0]\n",
    "\n",
    "    # X.shape = torch.Size([1000, 32])\n",
    "    # this is sequences of 1000 events x 32 samples per batch\n",
    "\n",
    "    if (i > 10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: FlexibleAE, optimizer, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    train the autoencoder model\n",
    "    \"\"\"\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # init loss metrics\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(dataloader, unit=\"batch\") as bar:\n",
    "        for batch in bar:\n",
    "            X = batch[0].permute(1,0).to(device)\n",
    "\n",
    "            latent = model.encoder(X)\n",
    "            reconstructed = model.decoder(latent)\n",
    "\n",
    "            loss = loss_fn(X, reconstructed)\n",
    "\n",
    "            # set zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backprop\n",
    "            loss.backward()\n",
    "\n",
    "            # step optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # update loss metrics\n",
    "            total_loss += loss.detach().item()\n",
    "\n",
    "            # update progress bar\n",
    "            bar.set_postfix(loss=loss.item())\n",
    "            bar.update()\n",
    "\n",
    "    # return the total loss (for plotting per epoch)\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [02:12<00:00,  3.89s/batch, loss=190]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333.18075875674975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FlexibleAE([1000, 512, 256])\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "LR = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "\n",
    "train(model, optimizer=optimizer, loss_fn=criterion, dataloader=train_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing songs to their encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music(metadata=Metadata(schema_version='0.2'), resolution=24, tracks=[Track(program=0, is_drum=False, notes=[Note(time=0, pitch=0, duration=923, velocity=64), Note(time=923, pitch=63, duration=77, velocity=64)])])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for one_batch in val_dataloader:\n",
    "    X = batch[0].permute(1,0).to(device)\n",
    "    \n",
    "    seq = X[0]\n",
    "    recon = model.forward(seq)\n",
    "\n",
    "\n",
    "    test = muspy.from_pitch_representation(np.asarray(seq, dtype=int))\n",
    "    test2 = muspy.from_pitch_representation(np.asarray(recon, dtype=int))\n",
    "    print(test)\n",
    "    # print(seq - recon)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
